---
title: "Arbres de Décision"
---

Il est maintenant temps d'introduire une seconde architecture de modèle. Comment prédiriez-vous la classe de l'observation inconnue **sans** utiliser de fonctions de distance ou de voisins les plus proches ?

![Nouvelle observation et données d'exemple](/images/trees/example_data.png){width=50%}

Une possibilité serait de **diviser les données à $x_1 = 2$**. Toute observation avec $x_1$ supérieur à $2$ serait classée comme $\circ$ ; le reste serait classé comme $\times$.

![Données d'exemple avec une seule division](/images/trees/split.png){width=50%}

## Divisions Multiples

Pour un cas plus complexe, comment prédiriez-vous la classe de l'observation inconnue avec ces données d'entraînement ? Comment diviseriez-vous les $\times$ des $\circ$ ?

![Un problème d'exemple plus complexe](/images/trees/complex_problem.png){width=50%}

Dans cet exemple, il n'y a **aucune ligne unique** qui puisse parfaitement séparer les deux groupes. En informatique, cela s'appelle aussi le **problème XOR**.

::: {.callout-note collapse="true"}
## Problème XOR

Le problème XOR (Ou Exclusif) fait référence à un problème fondamental en Machine Learning et en informatique dans lequel deux classes ne peuvent pas être séparées par une seule ligne droite. Il démontre **les faiblesses des modèles linéaires simples**.

![Problème XOR : Pouvez-vous trouver une seule ligne séparant les x des o ?](/images/trees/xor_problem.png){width=40%}

Le XOR est une opération logique qui prend deux valeurs booléennes (`Vrai`/`Faux` ou 1/0) en entrée et renvoie 1 (ou `Vrai`) si elles sont différentes et 0 ou `Faux` sinon. Vous pouvez voir la table de vérité de cette opération ci-dessous.

**Table de Vérité XOR**

| Entrée A | Entrée B | Sortie (A XOR B) |
|----------|----------|------------------|
| Faux     | Faux     | Faux             |
| Faux     | Vrai     | Vrai             |
| Vrai     | Faux     | Vrai             |
| Vrai     | Vrai     | Faux             |

Plus d'informations sur le problème XOR dans [@xorwiki]

:::

Au lieu de diviser les données une seule fois, et si vous pouviez diviser les données **plusieurs fois** ? Un exemple est montré ci-dessous :

![Diviser les données plusieurs fois](/images/trees/three_splits.png)

## Des Divisions aux Prédictions

En utilisant ces trois divisions, comment pourriez-vous classifier une **nouvelle observation** ?

Une façon de le faire serait de parcourir les divisions une par une :

- Si $x_1 \geq 2$ :
    - Si $x_2 \geq 1$ : assigner $\circ$
    - Sinon : assigner $\times$
- Sinon :
    - Si $x_2 \geq 2$ : assigner $\times$
    - Sinon : assigner $\circ$

L'observation se voit alors attribuer l'étiquette qui est la **majorité** dans la partition résultante.

:::{.exercise #exr-pred}
En utilisant la liste ci-dessus, générez des prédictions pour les observations suivantes :

- Observation 1 : $x_1 = 3, x_2 = 3$
- Observation 2 : $x_1 = 1, x_2 = 3$
- Observation 3 : $x_1 = 1, x_2 = 1$
:::

## De la Partition aux Arbres

La liste ci-dessus peut être difficile à suivre. Ce type de logique pourrait être représenté plus élégamment sous forme d'**arbre** (aussi appelé **Decision Tree**) :

![Visualiser les divisions comme un Decision Tree](/images/trees/tree_example.png)

:::{.exercise #exr-tree-pred}
Générez des prédictions pour les observations suivantes en descendant le Decision Tree ci-dessus :

- Observation 1 : $x_1 = 3, x_2 = 3$
- Observation 2 : $x_1 = 1, x_2 = 3$
- Observation 3 : $x_1 = 1, x_2 = 1$
:::

Pour mieux comprendre la relation entre les arbres et les divisions de données, l'arbre et la partition peuvent être visualisés côte à côte :

![Decision Tree comme partition de l'espace](/images/trees/tree_numbered_partition.png)

Chaque division ou comparaison crée une **séparation linéaire** dans l'espace des caractéristiques, représentée par une ligne noire dans le graphique ci-dessus.

En informatique, les arbres sont un type de graphe. Les graphes sont des collections de **nœuds et d'arêtes**.

![Les graphes sont des collections de nœuds et d'arêtes les connectant](/images/trees/basic_graph.png){width=40%}

Les arêtes peuvent être **orientées** ou **non orientées**. Les arêtes orientées ne peuvent être parcourues que dans une seule direction, généralement représentées par des flèches. Les arêtes, c'est-à-dire les connexions entre les nœuds, peuvent former des **cycles**. Ces cycles sont des chemins qui commencent et se terminent par le même nœud.

![Les arêtes peuvent être orientées](/images/trees/cycles_direction.png){width=40%}

:::{.exercise #exr-cycle}
Le diagramme ci-dessus met en évidence le cycle A→B→D→A. Pouvez-vous trouver un autre cycle ?
:::

Les arbres sont des **Graphes Acycliques Orientés** (DAGs). C'est un terme un peu technique, prenons ces termes un par un :

- **Orienté** : Ils vont de la racine vers les feuilles
- **Acyclique** : Ils ne contiennent pas de cycles ; il n'y a qu'un seul chemin de la racine vers chaque nœud

Voici un exemple d'arbre avec sept nœuds :

![Un arbre simple avec sept nœuds](/images/trees/tree_concepts.png){width=60%}

Les arbres, comme tous les graphes, sont composés de nœuds et d'arêtes. En plus du jargon habituel des graphes, il existe quelques concepts spécifiques aux arbres. Pour les comprendre, considérez l'exemple ci-dessus :

- **Nœuds parent et enfant** : tous deux connectés par une arête (nœuds B et D)
- **Nœud racine** : Le nœud le plus haut d'un arbre (nœud A)
- **Nœud feuille** : Un nœud sans enfants (nœud G)

:::{.exercise #exr-graph}
Trouvez un autre exemple de :

- Nœud feuille
- Nœud parent
:::

## Des Arbres aux Cartes

Tout comme le modèle KNN, les Decision Trees construisent une **carte** des caractéristiques d'entrée vers la variable cible. En utilisant un Decision Tree pour générer des prédictions pour toutes les valeurs de caractéristiques possibles, nous obtenons la carte suivante :

![Construire une carte avec les Decision Trees](/images/trees/decision_tree_partition_map.png){width=60%}

## Conclusion

Voilà, nous avons construit notre premier Decision Tree ! Nous pouvons utiliser ce modèle pour prédire n'importe quelle **nouvelle observation** en fonction de ses deux **caractéristiques** et de sa position sur la carte ci-dessus.

Ceci n'est qu'une introduction simple aux Decision Trees. Les prochains chapitres exploreront le fonctionnement interne de cette famille de modèles, en commençant par l'évaluation des divisions de données. Qu'est-ce qui fait une bonne division d'un ensemble de données ?

## Solutions

:::{.solution #sol-pred}
@exr-pred

- Observation 1 : $\circ$
- Observation 2 : $\times$
- Observation 3 : $\circ$
:::

:::{.solution #sol-tree-pred}
@exr-tree-pred

- Observation 1 : $\circ$
- Observation 2 : $\times$
- Observation 3 : $\circ$
:::

:::{.solution #sol-cycle}
@exr-cycle
Il y a de nombreux cycles possibles, voici deux exemples :

- C→D→C
- C→B→D→C
:::

:::{.solution #exr-graph}
@exr-graph

- Nœud feuille : D, E, F, G
- Nœud parent : A, B, C
:::
