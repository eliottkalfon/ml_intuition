---
title: Machine Learning et IA Générative
---

De nos jours, il est difficile d'écrire quoi que ce soit sur le Machine Learning sans mentionner l'Intelligence Artificielle Générative (GenAI). La GenAI a pris le monde d'assaut avec le lancement public de ChatGPT en 2022.

Décomposons ce terme :

- **Générative :** produisant du contenu tel que des textes, des images, de l'audio ou de la vidéo
- **Artificielle :** non humaine
- **Intelligence :** « la capacité d'apprendre, de comprendre et de formuler des jugements ou des opinions fondés sur la raison »[@cambridge_intelligence]

Plus généralement, l'intelligence artificielle peut être considérée comme l'émulation de l'intelligence humaine, définie ci-dessus. Des développements ultérieurs pourraient invalider cette définition à mesure que les algorithmes développés acquièrent des capacités dépassant la compréhension humaine.

La GenAI a été l'une des avancées technologiques majeures du début du 21e siècle. Elle a été construite sur une **combinaison des différents types de Machine Learning** énumérés [précédemment](defining-prediction.qmd).

## Commencer par les Fondations

La fondation des modèles GenAI est un **prédicteur du prochain mot (ou token)**. Lorsque nous envoyons une requête à un modèle GenAI, nous envoyons l'entrée suivante :

```
Utilisateur : Quelle est la capitale de la France ?

R :
```

Le modèle prend cette entrée et prédit `La` comme sortie.

La réponse serait un peu décevante si elle s'arrêtait là. Pour continuer, le modèle utilise la séquence d'entrée précédente et ajoute le token `La` qu'il a prédit :

```
Utilisateur : Quelle est la capitale de la France ?

R : La
```

et produit `capitale`. Ce processus continue jusqu'à ce que le modèle prédise un token `<fin>`, signifiant que la réponse est terminée. La pratique consistant à ajouter une prédiction à la séquence d'entrée originale pour générer une autre prédiction s'appelle **auto-régression**.

Note : Les grands modèles de langage (Large Language Models) ne prédisent pas le prochain mot mais le prochain **token**. Un token est une chaîne de caractères qui peut être une partie d'un mot (« ant ») ou un mot entier (« le »). Nous nous en tiendrons aux mots dans cette explication simplifiée.

::: {.exercise #exr-class}
Quel type de prédiction est la tâche de prédiction du prochain mot/token ?
:::

::: {.solution #sol-class}
C'est une tâche de classification, avec autant de labels que de mots/tokens possibles. Ce nombre est généralement appelé la **taille du vocabulaire**, qui dépasse légèrement 100 000 pour le modèle GPT-4 d'OpenAI.
:::

Bien qu'il s'agisse d'une tâche de classification, l'entraînement fondamental des grands modèles de langage est généralement qualifié d'apprentissage **auto-supervisé**, plutôt que simplement **supervisé**. C'est parce que, contrairement aux tâches de classification énumérées dans la section précédente, il n'y a pas de jeu de données d'entrées et de sorties. Le modèle est simplement entraîné à prédire le prochain mot de chaque phrase qu'il trouve.

À titre d'exemple, si le corpus d'entraînement contient la phrase :

> « La Seconde Guerre mondiale s'est terminée en 1945. »

Il inclurait les paires entrée/sortie suivantes dans son entraînement :

| Entrée                                      | Sortie   |
|---------------------------------------------|----------|
| La                                          | Seconde  |
| La Seconde                                  | Guerre   |
| La Seconde Guerre                           | mondiale |
| La Seconde Guerre mondiale                  | s'est    |
| La Seconde Guerre mondiale s'est            | terminée |
| La Seconde Guerre mondiale s'est terminée   | en       |
| La Seconde Guerre mondiale s'est terminée en| 1945     |
| La Seconde Guerre mondiale s'est terminée en 1945 | .  |

Vous pouvez voir que certaines prédictions sont beaucoup plus faciles que d'autres.

Le modèle de fondation est entraîné avec l'apprentissage supervisé car il apprend à partir de paires entrée/sortie. Pourtant, c'est auto-supervisé car ces paires entrée/sortie ne nécessitent pas de curation spéciale.

## La Prédiction du Prochain Mot Est-elle Suffisante ?

Si vous entraînez simplement un modèle à prédire le prochain mot en utilisant tout le texte d'internet, vous pourriez rencontrer des comportements surprenants. Par exemple, la requête :

> « 3 x 1 = »

pourrait recevoir la réponse :

> « 3, 3 x 2 = 6, 3 x 3 = 9 » …

C'est utile, mais seul « 3 » était nécessaire ici ; sauf si vous êtes dans le métier de la rédaction de manuels scolaires.

Dans ce cas, seule la réponse à « 3 x 1 » était nécessaire, et pourtant, la plupart des textes incluant la chaîne « 3 x 1 » listent simplement la table de multiplication de 3. Vous pourriez le vérifier en cherchant cette séquence de caractères dans les livres que vous avez chez vous, dont beaucoup devraient être des manuels de mathématiques élémentaires.

Plus de travail est nécessaire pour construire un modèle qui aide les utilisateurs et répond aux requêtes. Il y a deux principales façons de le faire.

## Apprendre à partir de Questions et Réponses

En plus d'utiliser le texte publié sur internet pour l'entraînement, on pourrait entraîner davantage un modèle de fondation à prédire le prochain mot de textes impliquant des questions et réponses **utiles**. Cela pourrait résoudre le problème décrit ci-dessus. Cet entraînement supplémentaire s'appelle **fine-tuning**. Il est appelé fine-tuning **supervisé** car au lieu d'apprendre à partir de textes bruts d'internet, il apprend à partir d'interactions question/réponse **sélectionnées**.

Par exemple, nous pouvons faire du fine-tuning sur le modèle avec les interactions suivantes :

```
Utilisateur : 3 x 2 =
Assistant : 3 x 2 = 6
```

```
Utilisateur : 7 x 2 =
Assistant : 7 x 2 = 14
```

etc.

Cela devrait entraîner le modèle à répondre à la requête de l'utilisateur au lieu de simplement compléter un texte. Le fine-tuning supervisé aide, mais n'est pas suffisant pour construire les modèles GenAI que nous utilisons au quotidien.

## Optimiser pour l'Utilité

L'objectif des fournisseurs de modèles GenAI est d'offrir des modèles aussi **utiles** que possible. Atteindre des degrés élevés d'utilité ne peut pas se faire uniquement par le pré-entraînement des modèles de fondation ou le fine-tuning supervisé.

À partir de ces deux étapes, l'utilité peut émerger comme un sous-produit (voir section précédente). À la place, pourrait-on optimiser un modèle pour l'utilité ? Si nous le pouvions, quel type de tâche de Machine Learning pourrions-nous utiliser ?

Indice : considérez le degré d'utilité comme une récompense que le modèle peut maximiser en choisissant le mot à utiliser dans sa réponse.

Si cela vous fait penser à l'[apprentissage par renforcement](types-ml.qmd), bravo. L'utilité est la **récompense** que le modèle essaierait de maximiser, et les mots qu'il utilise sont ses **actions**. Mais comment mesureriez-vous l'utilité ?

Premièrement, vous pourriez demander à des juges humains d'évaluer chaque sortie de modèle sur une échelle de 0 (pas utile) à 100 (incroyablement utile). Cela peut être problématique car les échelles d'utilité de différents humains peuvent varier. Peut-on faire mieux ?

Plus simple qu'une notation, les juges humains pourraient simplement choisir la plus utile de deux sorties de modèle. C'est ce qu'on appelle le **classement par paires**. Il présente plusieurs avantages :

- Il est moins exigeant cognitivement que la notation ou l'évaluation
- Il est plus robuste aux variations des échelles d'utilité individuelles

Pendant l'entraînement, le modèle apprendrait à générer des sorties plus utiles. C'est ce qu'on appelle l'**Apprentissage par Renforcement à partir de Retours Humains** (RLHF), la dernière brique de construction des modèles GenAI d'aujourd'hui.

::: {.callout-note collapse="true"}
## Au-delà du classement par paires humain

Une fois que nous avons rassemblé suffisamment d'exemples d'évaluations par paires humaines, nous pouvons entraîner un modèle à prédire le gagnant de deux suggestions candidates.

Ce faisant, nous revenons au territoire de l'apprentissage supervisé.

$$
\text{Entrée} \longrightarrow \text{Modèle} \longrightarrow \text{Prédiction}
$$

L'entrée ici serait les deux suggestions candidates, et la prédiction serait la prédiction gagnante ($0$ pour la première et $1$ pour la seconde). Les données d'entraînement sont toutes les suggestions candidates et les évaluations humaines collectées dans le processus décrit ci-dessus.

Cependant, ce n'est pas un problème de Machine Learning **tabulaire**. Les suggestions candidates sont deux séquences de texte de longueur variable. Cela fait partie du Traitement du Langage Naturel, un domaine de recherche fascinant.

:::

## Réflexions Finales

En essence, les modèles d'IA Générative sont des prédicteurs du prochain mot, entraînés davantage pour fournir des réponses plus utiles aux questions des utilisateurs. Ils sont construits sur les mêmes principes étudiés dans ce livre. La prédiction du prochain mot est encore une autre tâche de classification (complexe).

Cette description des grands modèles de langage (Large Language Models) est simplifiée. Veuillez vous référer à *Hands-on Large Language Models* [@alammar_grootendorst_2023] pour une présentation plus rigoureuse.
