---
title: Projet de Machine Learning de Bout en Bout
---

Il est maintenant temps de rassembler tout ce que nous avons étudié pour construire un modèle de Machine Learning capable de prédire **n'importe quoi**.

## Formulation du Problème

L'étape la plus importante est de **définir** le problème que vous souhaitez résoudre comme un problème d'apprentissage supervisé. En utilisant les exemples étudiés dans ce livre :

  - Quel est le diagnostic de cette masse suspecte ?
  - Quel est le prix de ce bien immobilier ?

Il existe de nombreux autres exemples. L'essentiel est de suivre le paradigme de l'apprentissage supervisé :

$$
\text{Variables d'Entrée} \rightarrow \text{Modèle} \rightarrow \text{Prédiction}
$$

Que voudriez-vous prédire pour résoudre un problème du quotidien ?

:::{.exercise #exr-probs}

Comment résoudriez-vous ces problèmes avec un modèle de Machine Learning ? Que prédiriez-vous ?

  1. Combien de barmans dois-je embaucher pour cette date ?
  2. Dois-je augmenter le stock d'un article particulier dans mon magasin ?
  3. Cette transaction en ligne est-elle frauduleuse ?
:::

## Métrique d'Évaluation

Maintenant que le problème est formulé comme une tâche d'apprentissage supervisé, sélectionnons une métrique d'erreur à minimiser. Cette métrique d'erreur devrait refléter les conséquences réelles d'une erreur.

Dans le cas du diagnostic de tumeur, les **Faux Négatifs**, c'est-à-dire les tumeurs malignes diagnostiquées comme « bénignes », peuvent avoir des conséquences fatales. Pour cette raison, le **Rappel** et le **Score F1** pourraient être des métriques intéressantes à suivre.

Dans l'exemple de l'estimation immobilière, des erreurs de prix extrêmes peuvent avoir un impact négatif sur toute entreprise immobilière. Pour cette raison, l'**Erreur Quadratique Moyenne** (MSE) ou la **Racine de l'Erreur Quadratique Moyenne** (RMSE) pourraient être de bons choix.

Vous pouvez souhaiter sélectionner plusieurs métriques d'erreur, mais vous devrez généralement en choisir une pour classer les différents modèles.


:::{.exercise #exr-err-met-sel}
Quelles métriques d'erreur choisiriez-vous pour les problèmes suivants ?

1. Détection de spam
2. Détection de fraude à la carte bancaire
3. Prédiction de l'attrition client
:::


## Collecte de Données

Maintenant que vous avez un problème, rassemblez autant de données pertinentes que possible. En gardant l'apprentissage supervisé à l'esprit, l'objectif est de donner au modèle suffisamment de données pour apprendre la relation entre les variables d'entrée et la variable cible.

En considérant l'exemple de l'estimation immobilière, le modèle devrait avoir accès à autant de caractéristiques pertinentes pour le prix que possible :

  - Surface
  - Nombre de pièces
  - Quartier
  - Balcon
  - Étage
  - etc…

C'est généralement une bonne idée d'inclure toute information sur le bien qui aiderait les humains à l'estimer, et un peu plus. Pourquoi plus ? Parce que les modèles peuvent parfois apprendre des patterns que nous ne pouvons pas percevoir.

:::{.exercise #exr-beer-sales}
Prévision des ventes de bière : Imaginez que vous voulez prévoir les ventes de bière dans votre bar. Quelles caractéristiques choisiriez-vous ?
:::

## Partitionnement des Données

Une fois que vous avez rassemblé les données, et avant de commencer le prétraitement, il est essentiel de mettre de côté une partie des données pour le test. Vous pourriez soit prendre un échantillon aléatoire des données, soit utiliser une date limite pour reproduire les conditions de prédiction du modèle.

Si vous développez un modèle d'estimation immobilière, vous pourriez vouloir garder les dernières semaines de votre ensemble d'entraînement comme ensemble de test, pour vous assurer que le modèle n'a pas accès aux tendances de prix futures lors de l'entraînement. Pour le cas du diagnostic de tumeur, un échantillon aléatoire de l'ensemble des données devrait suffire.

## Prétraitement des Données

Vous devrez très probablement nettoyer et prétraiter les données que vous avez rassemblées :

  - Y a-t-il des données manquantes ?
  - Les valeurs numériques sont-elles sur la même échelle ?
  - Comment souhaitez-vous traiter les variables de date ?
  - Y a-t-il des variables catégorielles à traiter ?

Note : différents modèles nécessitent parfois différents prétraitements. Comme il s'agit d'un texte d'introduction, nous laisserons les distinctions plus fines à des documents plus avancés. Comme exemple rapide, contrairement au K-Plus Proches Voisins (KNN), les Decision Trees ne nécessitent pas de mise à l'échelle des variables numériques.

Une fois que vous avez prétraité les données d'entraînement, appliquez les mêmes transformations sur l'ensemble de test, en utilisant les statistiques calculées avec les données d'entraînement. Si ce n'est pas assez clair, vous pouvez vous référer à la section Prétraitement des Données.

## Évaluation et Sélection des Modèles

C'est déjà beaucoup de travail, et nous n'avons toujours pas entraîné un seul modèle de Machine Learning. Bienvenue dans la réalité des professionnels du Machine Learning. Une grande partie de notre temps est consacrée à la formulation de problèmes, à la collecte et au prétraitement des données.

Maintenant, entraînez un modèle KNN et un modèle Decision Tree sur les données d'entraînement. Vous pouvez ensuite utiliser ces deux modèles pour générer des prédictions sur l'ensemble de test.

Avec ces prédictions, comparez la métrique d'erreur des deux modèles et choisissez le meilleur ! Vous pouvez ensuite utiliser ce modèle pour générer des prédictions sur de nouvelles observations. L'objectif de ce livre.

## Réflexions Finales

Ce chapitre a passé en revue les principales étapes de la résolution d'un problème avec des prédictions de Machine Learning :

  - Formulation du Problème
  - Métrique d'Évaluation
  - Collecte de Données
  - Partitionnement des Données
  - Prétraitement des Données
  - Évaluation et Sélection des Modèles

C'est tout ! L'objectif de ce livre était de donner une idée de ce à quoi peut ressembler la construction de solutions de Machine Learning. Les lecteurs intéressés peuvent explorer comment mettre ces connaissances en pratique avec des ressources supplémentaires comme : *Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow* [@hands_on_ml_2022].

L'Annexe ci-dessous explore certaines des différences entre la description faite ci-dessus et le Machine Learning en pratique.

Le chapitre suivant relie les modèles d'IA Générative au Machine Learning traditionnel ; montrant comment les modèles que nous utilisons quotidiennement ont été construits sur tout ce qui a été étudié dans ce livre.

## Annexe : Quelques Nuances

Ce chapitre présente une vision simplifiée de la pratique du Machine Learning. Si vous n'êtes pas intéressé par les détails, vous pouvez passer directement à la [conclusion](#réflexions-finales).

Premièrement, beaucoup de temps serait consacré à l'« **Ingénierie des Variables** » (Feature Engineering), la tâche de calculer des variables à partir de données brutes pour rendre les modèles plus précis.

Ensuite, la sélection de modèle impliquerait plus que deux modèles. Le livre a comparé deux familles de modèles : KNN et Decision Trees. Il en existe bien d'autres. La sélection de modèle impliquerait également l'« **Optimisation des Hyperparamètres** » (Hyperparameter Tuning). Ces hyperparamètres sont les réglages ou la configuration des modèles. Ils déterminent comment les modèles fonctionnent. Voici quelques exemples d'hyperparamètres :

  - **KNN** : Le nombre de voisins utilisés pour générer des prédictions. Le texte utilisait 5, mais 3, 10 ou 15 peuvent également être des choix viables
  - **Decision Tree** : la profondeur maximale d'un arbre, pour éviter de faire trop de divisions de données

Pour choisir parmi toutes ces familles de modèles et combinaisons d'hyperparamètres, un seul ensemble de test ne suffit pas. Les praticiens du ML utilisent généralement la **validation croisée** sur l'ensemble d'entraînement. Le lecteur intéressé peut en apprendre davantage à ce sujet dans [@sklearn_cross_validation_2025].

## Réflexions Finales

C'est tout. Vous avez maintenant une intuition du flux de travail du Machine Learning. C'était l'objectif principal de ce livre.

Mais qu'en est-il de l'IA Générative et des LLMs ? Je pensais que vous n'alliez jamais demander. Si vous êtes intéressé par la compréhension des nombreux parallèles entre le Machine Learning traditionnel et les LLMs, lisez les prochains chapitres.

Sinon, je vous souhaite le meilleur dans votre parcours en Machine Learning.

## Solutions

:::{.solution #sol-probs}
@exr-probs

  1. Combien de personnel dois-je embaucher pour cette date à mon bar ? Prévision des ventes de bière
  2. Dois-je augmenter le stock d'un article particulier dans mon magasin ? Prévision des ventes unitaires
  3. Cette transaction en ligne est-elle frauduleuse ? Classification de la transaction comme « légitime »/« frauduleuse »

:::

:::{.solution #sol-err-met-sel}
@exr-err-met-sel

1. Détection de spam : Précision, Rappel, Exactitude. Un Faux Positif, un email légitime marqué comme « spam » peut être plus problématique qu'un Faux Négatif, un email de spam classé comme « légitime ».
2. Détection de fraude à la carte bancaire : Rappel, Précision, Score F1. Le modèle devrait détecter la plupart des transactions frauduleuses (Rappel élevé) tout en n'ayant pas trop de Faux Positifs, car ils pourraient être un inconvénient pour les clients.
3. Prédiction de l'attrition client : Score F1. Un équilibre entre la Précision et le Rappel est nécessaire pour identifier les clients susceptibles de partir sans avoir trop de Faux Positifs.
:::

:::{.solution #sol-beer-sales}
@exr-beer-sales

Voici quelques caractéristiques potentielles pour la prévision des ventes de bière :

  - **Date/Heure** : Mois, jour de la semaine, heure de la journée.
  - **Météo** : Température, pluie, soleil.
  - **Événements** : Y a-t-il des événements majeurs dans la ville, comme un match de football ou un concert ?
  - **Promotions** : Y a-t-il une offre spéciale sur la bière ?
  - **Données historiques de ventes** : Ventes des jours, semaines ou mois précédents.
:::
